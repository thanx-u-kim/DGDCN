{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3a5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc7bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "import time\n",
    "import osmnx as ox\n",
    "# import folium\n",
    "import pickle\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "from leuvenmapmatching.matcher.distance import DistanceMatcher\n",
    "from leuvenmapmatching.map.inmem import InMemMap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b61660f",
   "metadata": {},
   "source": [
    "## Network Generation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba11fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Study area definition with Coordinates.\n",
    "# Point = (Longitude, Latitude)\n",
    "\n",
    "p1_buffer = (127.052866, 37.521370)\n",
    "p2_buffer = (127.065862, 37.493310)\n",
    "p3_buffer = (126.997581, 37.471532)\n",
    "p4_buffer = (126.985552, 37.501859)\n",
    "\n",
    "area_buffer = Polygon([p1_buffer, p2_buffer, p3_buffer, p4_buffer])\n",
    "\n",
    "graph = ox.graph_from_polygon(area_buffer, network_type='drive', truncate_by_edge=True, clean_periphery=True, custom_filter='[\"highway\"~\"primary|secondary|tertiary\"]')\n",
    "\n",
    "graph_proj = ox.project_graph(graph)\n",
    "graph_consolidated = ox.consolidate_intersections(graph_proj, rebuild_graph=True, tolerance=22, dead_ends=False)\n",
    "\n",
    "graph_proj4326 = ox.project_graph(graph_consolidated, to_crs='EPSG:4326') # Geographic coordinate reference system (EPSG:4326)\n",
    "graph_nodes, graph_edges = ox.graph_to_gdfs(graph_proj4326, nodes=True, edges=True)\n",
    "\n",
    "print(len(graph_edges))\n",
    "ox.plot.plot_graph(graph_consolidated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331cc46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_nodes['lon'] = graph_nodes.apply(lambda x: x['x'], axis=1)\n",
    "graph_nodes['lat'] = graph_nodes.apply(lambda x: x['y'], axis=1)\n",
    "\n",
    "graph_nodes.reset_index(inplace=True)\n",
    "\n",
    "graph_nodes['osmid_new'] = np.nan\n",
    "for i in range(len(graph_nodes)):\n",
    "    graph_nodes['osmid_new'][i] = i\n",
    "\n",
    "graph_nodes.set_index('osmid_new', drop=False, inplace=True)\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "graph_edges = graph_edges.copy()\n",
    "graph_edges.reset_index(drop=False, inplace=True)\n",
    "# graph_edges.drop(['tunnel', 'lanes', 'access', 'ref', 'maxspeed', 'bridge'], axis=1, inplace=True)\n",
    "\n",
    "nodes_list = graph_nodes[['osmid', 'osmid_new']]\n",
    "nodes_list.columns = ['u', 'u_new']\n",
    "\n",
    "graph_edges = pd.merge(graph_edges, nodes_list, how='left', on='u')\n",
    "\n",
    "nodes_list = graph_nodes[['osmid', 'osmid_new']]\n",
    "nodes_list.columns = ['v', 'v_new']\n",
    "\n",
    "graph_edges = pd.merge(graph_edges, nodes_list, how='left', on='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c59194",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_con = InMemMap('Arbitrary_Area', use_rtree=False, index_edges=True)\n",
    "\n",
    "for nid, row in graph_nodes[['lat', 'lon']].iterrows():\n",
    "    map_con.add_node(nid, (row['lat'], row['lon']))\n",
    "for nid, row in graph_edges[['u_new', 'v_new']].iterrows():\n",
    "    map_con.add_edge(row['u_new'], row['v_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b708d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_edges = graph_edges.copy()\n",
    "network_edges['Link'] = network_edges.apply(lambda x: (x.u_new, x.v_new), axis=1)\n",
    "network_edges = network_edges[['Link', 'name', 'length', 'geometry']]\n",
    "network_edges.reset_index(drop=False, inplace=True)\n",
    "network_edges.rename(columns={'index': 'EdgeID'}, inplace=True)\n",
    "network_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e66106",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_EdgeID = network_edges[['Link', 'EdgeID']]\n",
    "network_EdgeID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70909ebf",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_call(day, category, order, extension): # category = [data, traj], extension = [pkl, pickle]\n",
    "    directory = './DTGoutput'+format(day, '02')+'/'\n",
    "    filename = str(category)+'_'+format(day, '02')+'_'+format(order, '03')+'.'+str(extension)\n",
    "    full_name = directory + filename\n",
    "    return full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_save(day, category, order, extension): # category = [data, traj], extension = [pkl, pickle]\n",
    "    model_object_file_path = './Mapmatching_output/18-04-'+format(day, '02')\n",
    "    if not os.path.exists(model_object_file_path):\n",
    "        os.makedirs(model_object_file_path)\n",
    "    directory = model_object_file_path+'/'\n",
    "    filename = str(category)+'_'+format(day, '02')+'_'+format(order, '03')+'.'+str(extension)\n",
    "    full_name = directory + filename\n",
    "    return full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Applying_Mapmatching(df, area, traj_dict):\n",
    "    samples = pd.DataFrame()\n",
    "    matcher = DistanceMatcher(area, max_dist=300, min_prob_norm=0.5, obs_noise=50)\n",
    "    TripID_list = list(traj_dict.keys())\n",
    "    counts = 0\n",
    "    \n",
    "    for idx in TripID_list:\n",
    "        states, _ = matcher.match(traj_dict[idx])\n",
    "        if not states:\n",
    "            pass\n",
    "        if states:\n",
    "            sample_id_order = [str(idx)+'_'+str(k+1) for k in range(len(df[df.TripID == idx]))]\n",
    "            sample_data = {'TripID_order': sample_id_order, 'Link': states}\n",
    "            sample = pd.DataFrame(dict([(k, pd.Series(v)) for k,v in sample_data.items()]))\n",
    "            samples = pd.concat([samples, sample])\n",
    "\n",
    "        counts += 1\n",
    "    \n",
    "    dataframe = pd.merge(df, samples, how='left', on='TripID_order')\n",
    "    dataframe.dropna(subset=['Link'], inplace=True)\n",
    "    dataframe.reset_index(drop=True, inplace=True)\n",
    "    dataframe = pd.merge(dataframe, network_EdgeID, how='left', on='Link')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d234d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network_Speed(dataframe):\n",
    "    avg_speed = dataframe.groupby(dataframe['Link']).Speed.mean() ## 10분 간 링크별 평균 속도\n",
    "    return avg_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Connectivity_Adj(dataframe, edge_number):\n",
    "    # initializing the conenctivity adjacency matrix\n",
    "    connect_adj = torch.zeros(edge_number, edge_number)\n",
    "    \n",
    "    # EdgeID list generation\n",
    "    EdgeID_list = list(dataframe.EdgeID.unique())\n",
    "    \n",
    "    # Updating the conenctivity adjacency matrix\n",
    "    for idx in EdgeID_list:\n",
    "        in_num = dataframe.Link.loc[idx][0]\n",
    "        out_num = dataframe.Link.loc[idx][1]\n",
    "        \n",
    "        for i in range(edge_number):\n",
    "            if dataframe.Link.iloc[i][1] == in_num:\n",
    "                if dataframe.Link.iloc[i][0] == out_num:\n",
    "                    connect_adj[idx, dataframe.EdgeID.iloc[i]] = 0\n",
    "                else:\n",
    "                    connect_adj[idx, dataframe.EdgeID.iloc[i]] += 1\n",
    "            elif dataframe.Link.iloc[i][0] == out_num:\n",
    "                connect_adj[idx, dataframe.EdgeID.iloc[i]] += 1\n",
    "            else:\n",
    "                pass\n",
    "        connect_adj[idx, idx] = 0\n",
    "        \n",
    "    return connect_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa239db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generating_FlowAdj(dataframe, edge_number):\n",
    "    # initializing the traffic inflow and outflow adjacency matrix\n",
    "    edge_number = len(network_edges)\n",
    "    a_inflow = torch.zeros(edge_number, edge_number)\n",
    "    a_outflow = torch.zeros(edge_number, edge_number)\n",
    "    \n",
    "    # TripID list generation\n",
    "    ID_list = list(dataframe.TripID.unique())\n",
    "    \n",
    "    # Updating the traffic inflow & outflow adjacency matrix\n",
    "    for i in ID_list:\n",
    "        sample = dataframe[dataframe.TripID == i]\n",
    "        if len(sample) <= 1:\n",
    "            pass\n",
    "        else:\n",
    "            for j in range(len(sample)-1):\n",
    "                if sample.EdgeID.iloc[j] == sample.EdgeID.iloc[j+1]:\n",
    "                    pass\n",
    "                else:\n",
    "                    a_inflow[sample.EdgeID.iloc[j+1], sample.EdgeID.iloc[j]] += 1 ## In tensor: row = to, column = from\n",
    "                    a_outflow[sample.EdgeID.iloc[j], sample.EdgeID.iloc[j+1]] += 1 ## In tensor: row = from, column = to\n",
    "    return a_inflow, a_outflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a140c1ac",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70768d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Target day\n",
    "daycount = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e14c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = len(network_EdgeID)\n",
    "adj_con = Connectivity_Adj(network_EdgeID, number)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(0, 144):\n",
    "    # Name definition...\n",
    "    dataname = name_call(day=daycount, category='data', order=i, extension='pkl') # category = [data, traj], extension = [pkl, pickle]\n",
    "    trajname = name_call(day=daycount, category='traj', order=i, extension='pickle') # category = [data, traj], extension = [pkl, pickle]\n",
    "    inflow_name = name_save(day=daycount, category='in_flow', order=i, extension='pkl')\n",
    "    outflow_name = name_save(day=daycount, category='out_flow', order=i, extension='pkl')\n",
    "    network_speed_name = name_save(day=daycount, category='speed', order=i, extension='pkl')\n",
    "    \n",
    "    # Data Loading...\n",
    "    try:\n",
    "        data1 = pd.read_pickle(dataname)\n",
    "        with open(trajname, 'rb') as f:\n",
    "            data2 = pickle.load(f)\n",
    "    except: # If the file is missing, skip to the next iteration.\n",
    "        continue\n",
    "    \n",
    "    # Map Matching...\n",
    "    try:\n",
    "        matched_dataframe = Applying_Mapmatching(data1, map_con, data2)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Average Speed Dataframe\n",
    "    average_speed = Network_Speed(matched_dataframe)\n",
    "    network_speed = pd.merge(network_edges, average_speed, how='left', on='Link')\n",
    "    \n",
    "    # Working Flow Adjacency Matrix...\n",
    "    inflow_adj, outflow_adj = Generating_FlowAdj(matched_dataframe, number)\n",
    "    inflow_revised = torch.mul(inflow_adj, adj_con) # Hadamard multiplication — reset incorrectly counted flows\n",
    "    outflow_revised = torch.mul(outflow_adj, adj_con) # Hadamard multiplication — reset incorrectly counted flows\n",
    "    \n",
    "    # Save Output...\n",
    "    torch.save(inflow_revised, inflow_name) ## save to pickle\n",
    "    torch.save(outflow_revised, outflow_name) ## save to pickle\n",
    "    network_speed.to_pickle(network_speed_name) ## save to pickle\n",
    "    \n",
    "print(f'Task completed...\\nElapsed time: {time.time()-start}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
